{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, load_metric\n",
    "import torch\n",
    "\n",
    "# Load the datasets\n",
    "ariq = pd.read_csv('comments - ariq.csv')\n",
    "fadel = pd.read_csv('comments - fadel.csv')\n",
    "kemas = pd.read_csv('comments - kemas.csv')\n",
    "\n",
    "# Combine all dataframes\n",
    "df = pd.concat([ariq, fadel, kemas])\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns={'(1: positif, 0: negatif, 2: netral)': 'Sentiment'}, inplace=True)\n",
    "\n",
    "# Drop rows where Sentiment is NaN\n",
    "df.dropna(subset=['Sentiment'], inplace=True)\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # remove mentions\n",
    "    text = re.sub(r'#', '', text)  # remove hashtag symbol\n",
    "    text = re.sub(r'RT[\\s]+', '', text)  # remove RT\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)  # remove hyperlink\n",
    "    text = re.sub(r'\\n', '', text)  # remove newline\n",
    "    return text\n",
    "\n",
    "# Apply clean_text function\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Remove emojis\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply remove_emoji function\n",
    "df['text'] = df['text'].apply(remove_emoji)\n",
    "\n",
    "# Ensure Sentiment column is of integer type\n",
    "df['Sentiment'] = df['Sentiment'].astype(int)\n",
    "\n",
    "# Split the dataset\n",
    "train_df, eval_df = train_test_split(df[[\"text\", \"Sentiment\"]], test_size=0.2, random_state=23)\n",
    "\n",
    "# Convert text column to string\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "eval_df['text'] = eval_df['text'].astype(str)\n",
    "\n",
    "# Create Hugging Face datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Define the tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Apply the tokenize function to the dataset\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Ensure the tokenized datasets have the correct format\n",
    "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"Sentiment\", \"labels\")\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.rename_column(\"Sentiment\", \"labels\")\n",
    "\n",
    "# Set the format of the datasets to tensors\n",
    "tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_eval_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# # Load the pre-trained model\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"indobenchmark/indobert-base-p2\", num_labels=3)\n",
    "\n",
    "# # Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=100,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "# # Define the Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_train_dataset,\n",
    "#     eval_dataset=tokenized_eval_dataset,\n",
    "#     compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).mean()}\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"indobenchmark/indobert-base-p2\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 0 2 1 1 1 1 2 0 2 2 0 0 1 1 2 1 0 1 0 0 0 2 1 1 1 0 1 0 1 1\n",
      " 1 0 1 0 2 2 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 2 0 2 1 1 2 1\n",
      " 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 0 1 1 2 0 1 1 1 2 2 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 2 1 0 0\n",
      " 1 1 1 2 1 1 0 2 1 1 0 2 0 1 1 1 0 1 2 1 0 1 1 0 1 0 0 0 1 1 2 1 2 0 1 1 1\n",
      " 0 1 0 0 2 2 0 1 0 0 0 2 1 1 1 1 1 1 1 1 1 2 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1\n",
      " 2 0 0 0 1 0 2 2 1 1 0 1 1 1 0 0 1 1 1 1 2 1 0 1 1 1 1 0 1 0 1 0 1 1 1 2 1\n",
      " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 2 0 1 1 1 1 2 1 0 1 2 1 1 0 1 2 0 0 1\n",
      " 1 2 2 1 1 1 0 0 2 1 0 1 0 0 2 2 1 1 0 0 0 2 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0\n",
      " 1 0 2 1 1 2 0 2 0 1 2 0 1 1 1 0 2 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Perform inference on eval dataset\n",
    "eval_predictions = []\n",
    "\n",
    "# Set up the DataLoader\n",
    "eval_dataloader = torch.utils.data.DataLoader(tokenized_eval_dataset, batch_size=8)\n",
    "\n",
    "# Move model to the same device as the data\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Iterate over batches\n",
    "for batch in eval_dataloader:\n",
    "    with torch.no_grad():\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Extract predicted labels\n",
    "    predictions = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "    eval_predictions.extend(predictions)\n",
    "\n",
    "# Convert predicted labels to numpy array\n",
    "eval_predictions = np.array(eval_predictions)\n",
    "\n",
    "# Print or use eval_predictions for further analysis\n",
    "print(eval_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = eval_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 2, 0, 2, 1, 1, 1, 2, 0, 0, 2, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1,\n",
       "       0, 2, 0, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "       1, 2, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 2, 0,\n",
       "       2, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 1, 2, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       2, 1, 1, 2, 0, 0, 2, 2, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0,\n",
       "       1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 1,\n",
       "       1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2,\n",
       "       1, 1, 2, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 0,\n",
       "       1, 2, 1, 1, 0, 1, 2, 0, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 2, 1, 1, 2, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 1, 2, 1, 1, 1, 0, 2, 1, 2,\n",
       "       1, 1, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te = np.array(eval_df['Sentiment'])\n",
    "y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(eval_df[\"Sentiment\"], eval_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negatif', 'Netral', 'Positif'], yticklabels=['Negatif', 'Netral', 'Positif'])\n",
    "plt.xlabel('Prediksi')\n",
    "plt.ylabel('Sebenarnya')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.80      0.75      0.77       118\n",
      "      Netral       0.75      0.89      0.82       171\n",
      "     Positif       0.42      0.28      0.33        69\n",
      "\n",
      "    accuracy                           0.73       358\n",
      "   macro avg       0.66      0.64      0.64       358\n",
      "weighted avg       0.71      0.73      0.71       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(eval_df[\"Sentiment\"], eval_predictions, target_names=['Negatif', 'Netral', 'Positif'])\n",
    "\n",
    "# Print classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "np.round(accuracy_score(y_te, y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9997842e-01 9.0245230e-06 1.2481080e-05]\n",
      " [9.9995720e-01 3.1191583e-05 1.1558047e-05]\n",
      " [9.3235285e-06 9.9997926e-01 1.1465325e-05]\n",
      " ...\n",
      " [9.6218773e-06 9.9997962e-01 1.0732670e-05]\n",
      " [9.9997926e-01 9.0565509e-06 1.1701721e-05]\n",
      " [9.9994504e-01 4.7779347e-05 7.1967952e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Perform inference on eval dataset\n",
    "eval_probabilities = []\n",
    "\n",
    "# Set up the DataLoader\n",
    "eval_dataloader = torch.utils.data.DataLoader(tokenized_eval_dataset, batch_size=8)\n",
    "\n",
    "# Move model to the same device as the data\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Iterate over batches\n",
    "for batch in eval_dataloader:\n",
    "    with torch.no_grad():\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Apply softmax to logits to get probabilities\n",
    "    probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()\n",
    "    eval_probabilities.extend(probs)\n",
    "\n",
    "# Convert probabilities to numpy array\n",
    "eval_probabilities = np.array(eval_probabilities)\n",
    "\n",
    "c = eval_probabilities\n",
    "# Print or use eval_probabilities for further analysis\n",
    "print(eval_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424730200419935"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_te, c, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.274"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate hamming loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "np.round(hamming_loss(y_te, y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
